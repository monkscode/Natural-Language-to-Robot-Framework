# The model provider to use. Can be "online" or "local".
MODEL_PROVIDER=online

# The online model to use (e.g., "gemini-1.5-flash", "gemini-2.0-flash-exp").
# This is only used if MODEL_PROVIDER is "online".
# Note: Use model name WITHOUT "gemini/" prefix for LiteLLM
ONLINE_MODEL=gemini/gemini-2.5-flash

# The local model to use with Ollama (e.g., "qwen2.5-coder:14b").
# This is only used if MODEL_PROVIDER is "local".
LOCAL_MODEL=qwen2.5-coder:14b

# The port the FastAPI server should bind to when started via run.sh or uvicorn.
APP_PORT=5000

# --- Service Endpoints ---
# Vision BrowserUse service used for live locator extraction during generation/healing.
BROWSER_USE_SERVICE_URL=http://localhost:4999

# --- Browser Configuration ---
# Browser headless mode for BrowserUse service element detection
# When true: Browser runs without UI (faster, for CI/CD)
# When false: Browser UI visible (for debugging/development)
# Default: true
BROWSER_HEADLESS=true

# --- Gemini Configuration ---
# Your Google Gemini API key. This is required if MODEL_PROVIDER is "online".
GEMINI_API_KEY=

# --- Robot Framework Library Configuration ---
# The Robot Framework library to use for test generation.
# Options: "selenium" (SeleniumLibrary) or "browser" (Browser Library with Playwright)
# Recommendation: Use "browser" for new projects and modern websites
# Default: browser
ROBOT_LIBRARY=browser

# --- Agent Retry Configuration ---
# Maximum iterations for agents with delegation enabled (retry attempts)
# Valid range: 1-5
# Default: 3
MAX_AGENT_ITERATIONS=3

# --- Custom Actions Configuration ---
# true/false custom actions for browser automation
# When true, the agent can call custom actions like find_unique_locator
# When false, the agent will call javascript functions
# Default: true (RECOMMENDED)
ENABLE_CUSTOM_ACTIONS=true

# Timeout for custom action execution (in seconds)
# Default: 5
CUSTOM_ACTION_TIMEOUT=5

# Maximum number of locator strategies to try when finding unique locators
# Default: 21
MAX_LOCATOR_STRATEGIES=21

# Enable/disable LLM cost tracking and logging
# Default: true
TRACK_LLM_COSTS=true

# --- Docker Configuration ---
# Whether to prefer pulling pre-built images from Docker Hub before building locally
# When true: Try to pull monkscode/nlrf:latest first, fallback to local build
# When false: Always build locally (useful for development/customization)
# Default: true (RECOMMENDED for faster setup)
PREFER_REMOTE_DOCKER_IMAGE=true

# Custom remote Docker image to pull (only used if PREFER_REMOTE_DOCKER_IMAGE=true)
# Leave empty to use the default: monkscode/nlrf:latest
# Example: your-org/custom-nlrf:latest
REMOTE_DOCKER_IMAGE=monkscode/nlrf:latest

# --- Docker Compose Configuration ---
# Image tags for docker-compose deployment
# Set to specific versions (e.g., "monkscode/nlrf-fastapi:v1.0.0") or use "latest"
FASTAPI_IMAGE_TAG=monkscode/nlrf-fastapi:latest
BROWSER_SERVICE_IMAGE_TAG=monkscode/nlrf-browser-service:latest

# Host absolute path for robot_tests directory (Docker-in-Docker support)
# This is required when running inside Docker to mount volumes correctly in spawned test containers
# For local development: Leave empty (auto-detected)
# For Docker deployment: Set to host machine's absolute path (e.g., /home/user/project/robot_tests)
# Example: /var/lib/docker/volumes/nlrf_robot_tests/_data
HOST_ROBOT_TESTS_DIR=


# --- CrewAI Performance Optimization Configuration ---
# Enable/disable the optimization system (pattern learning, ChromaDB, semantic search)
# When enabled, reduces token usage by 67% through hybrid knowledge architecture
# Default: false (disabled until fully tested)
OPTIMIZATION_ENABLED=true

# Path to ChromaDB storage directory for keyword embeddings
# ChromaDB stores keyword documentation with semantic search capabilities
# Default: ./chroma_db
OPTIMIZATION_CHROMA_DB_PATH=./chroma_db

# Path to SQLite database for pattern learning
# Stores query patterns and keyword usage history for prediction
# Default: ./data/pattern_learning.db
OPTIMIZATION_PATTERN_DB_PATH=./data/pattern_learning.db

# Number of keywords to return from semantic search
# Higher values provide more options but increase token usage
# Valid range: 1-10
# Default: 3
OPTIMIZATION_KEYWORD_SEARCH_TOP_K=3

# Minimum confidence threshold for pattern prediction (0.0-1.0)
# Higher values require stronger similarity matches before using predictions
# 0.7 = 70% similarity required
# Default: 0.7
OPTIMIZATION_PATTERN_CONFIDENCE_THRESHOLD=0.7

# Enable/disable smart context pruning based on query classification
# When enabled, only includes keywords relevant to detected action types
# Reduces context size by ~40% while maintaining accuracy
# Default: true
OPTIMIZATION_CONTEXT_PRUNING_ENABLED=true

# Minimum confidence threshold for category classification (0.0-1.0)
# Higher values require stronger category matches before pruning
# 0.6 = 60% similarity required
# Default: 0.6
OPTIMIZATION_CONTEXT_PRUNING_THRESHOLD=0.6
