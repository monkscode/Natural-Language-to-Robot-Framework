# Mark 1 - Natural Language to Robot Framework

![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)
![Python](https://img.shields.io/badge/Python-3.9%2B-green.svg)
![Robot Framework](https://img.shields.io/badge/Robot%20Framework-6.0%2B-orange.svg)
![Docker](https://img.shields.io/badge/Docker-Required-blue.svg)

Transform natural language test descriptions into executable Robot Framework code using advanced AI agents. Mark 1 is an intelligent test automation platform that bridges the gap between human language and automated testing.

## âœ¨ Key Features

- ğŸ¤– **Multi-Agent AI System**: Sophisticated pipeline with specialized agents for planning, identification, validation, and self-correction
- ğŸ”„ **Self-Healing Tests**: Automatic error detection and correction through intelligent validation loops
- ğŸ³ **Containerized Execution**: Clean, isolated test runs in Docker containers for consistent results
- ğŸŒ **Flexible Model Support**: Works with both local LLMs (via Ollama) and cloud models (Google Gemini)
- ğŸ“Š **Detailed Reporting**: Comprehensive HTML logs and reports for easy debugging
- âš¡ **Real-time Streaming**: Live progress updates and instant feedback
- ğŸ¯ **Smart Element Detection**: AI-powered web element locator generation

## ğŸ—ï¸ Architecture

Mark 1 employs a sophisticated multi-agent workflow powered by CrewAI:

### Core Workflow Agents
1. **Step Planner Agent** - Decomposes natural language into structured test plans
2. **Element Identifier Agent** - Generates optimal web element locators using AI-powered browser automation
3. **Code Assembler Agent** - Creates syntactically correct Robot Framework code
4. **Validator Agent** - Ensures code quality and correctness
5. **Self-Correction Orchestrator** - Automatically fixes validation errors

### Self-Healing System
- **Healing Orchestrator** - Coordinates automatic test repair when failures occur
- **Failure Detection Service** - Identifies healable failures in test execution
- **Healing Agents** - Specialized agents for locator regeneration and test repair
- **Fingerprinting Service** - Tracks element characteristics for intelligent healing
- **Structural Fallback System** - Provides structural similarity analysis for element matching

### Supporting Services
- **Docker Service** - Manages isolated test execution in containers
- **Chrome Session Manager** - Handles browser sessions for element identification
- **BrowserUse Service** - AI-powered browser automation for locator extraction
- **Workflow Service** - Orchestrates the end-to-end test generation pipeline

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.9+** - [Download Python](https://python.org/downloads/)
- **Docker** - [Install Docker](https://docs.docker.com/get-docker/)
- **Git** - [Install Git](https://git-scm.com/downloads)
- **(Optional) Ollama** - For local AI models [Install Ollama](https://ollama.com/)

### Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd natural-language-robot-framework
   ```

2. **Configure your AI model**
   ```bash
   cp src/backend/.env.example src/backend/.env
   ```

   **For Google Gemini (Recommended)**:
   ```env
   MODEL_PROVIDER=online
   GEMINI_API_KEY="your-gemini-api-key-here"
   ONLINE_MODEL=gemini-2.5-pro
   ```

   **For Local Models (Ollama)**:
   ```env
   MODEL_PROVIDER=local
   LOCAL_MODEL=llama3
   ```

3. **Start the application**
   ```bash
   # Linux/macOS
   chmod +x run.sh
   ./run.sh

   # Windows (Git Bash)
   bash run.sh
   ```

4. **Access the web interface**
   Open your browser to `http://localhost:<APP_PORT>` (default `5000`)

## ğŸ’¡ Usage Examples

Simply describe your test in natural language:

### Basic Examples
- *"Open Google, search for 'Robot Framework tutorials', and click the first result"*
- *"Navigate to GitHub, search for 'selenium automation', and star the top repository"*
- *"Go to YouTube, search for 'Python automation', and play the first video"*

### Advanced Examples
- *"Visit Amazon, search for 'wireless headphones', filter by rating above 4 stars, and add the top result to cart"*
- *"Open LinkedIn, search for 'QA Engineer' jobs in San Francisco, and apply filters for remote work"*
- *"Navigate to Stack Overflow, search for 'pytest fixtures', and upvote the most helpful answer"*

## ğŸ› ï¸ Configuration

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `MODEL_PROVIDER` | AI model provider (`online` or `local`) | `online` |
| `GEMINI_API_KEY` | Google Gemini API key | Required for online |
| `ONLINE_MODEL` | Gemini model name | `gemini-2.5-pro` |
| `LOCAL_MODEL` | Ollama model name | `llama3` |
| `APP_PORT` | FastAPI server port used by `run.sh` | `5000` |
| `BROWSER_USE_SERVICE_URL` | BrowserUse service base URL for locator extraction + vision validation | `http://localhost:4999` |

### Getting API Keys

**Google Gemini API Key**:
1. Visit [Google AI Studio](https://aistudio.google.com/app/apikey)
2. Create a new API key
3. Copy the key to your `.env` file

## ğŸ§ª Testing

Test the API endpoint directly:

```bash
chmod +x test.sh
./test.sh
```

Or use curl:

```bash
curl -X POST \
   -H "Content-Type: application/json" \
   -d '{"query": "go to google.com and search for python tutorials", "model": "gemini-1.5-pro-latest"}' \
   http://localhost:${APP_PORT:-5000}/generate-and-run
```

## ğŸ“ Project Structure

```
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ backend/
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”œâ”€â”€ endpoints.py           # Main API endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ healing_endpoints.py   # Self-healing API endpoints
â”‚   â”‚   â”‚   â””â”€â”€ monitoring_endpoints.py# Monitoring and metrics API
â”‚   â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py              # Configuration management
â”‚   â”‚   â”‚   â”œâ”€â”€ config_loader.py       # Healing configuration loader
â”‚   â”‚   â”‚   â”œâ”€â”€ logging_config.py      # Logging setup
â”‚   â”‚   â”‚   â”œâ”€â”€ metrics.py             # Metrics collection
â”‚   â”‚   â”‚   â””â”€â”€ models/                # Data models
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ docker_service.py      # Docker container management
â”‚   â”‚   â”‚   â”œâ”€â”€ workflow_service.py    # Main workflow orchestration
â”‚   â”‚   â”‚   â”œâ”€â”€ healing_orchestrator.py# Self-healing coordinator
â”‚   â”‚   â”‚   â”œâ”€â”€ failure_detection_service.py # Failure detection
â”‚   â”‚   â”‚   â”œâ”€â”€ chrome_session_manager.py    # Browser session management
â”‚   â”‚   â”‚   â”œâ”€â”€ fingerprinting_service.py    # Element fingerprinting
â”‚   â”‚   â”‚   â”œâ”€â”€ structural_fallback_system.py# Structural similarity
â”‚   â”‚   â”‚   â”œâ”€â”€ test_code_updater.py   # Updates test code with healed locators
â”‚   â”‚   â”‚   â”œâ”€â”€ dom_analyzer.py        # DOM analysis utilities
â”‚   â”‚   â”‚   â””â”€â”€ similarity_scorer.py   # Similo algorithm for element matching
â”‚   â”‚   â”œâ”€â”€ crew_ai/
â”‚   â”‚   â”‚   â”œâ”€â”€ agents.py              # CrewAI agent definitions
â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.py               # CrewAI task definitions
â”‚   â”‚   â”‚   â”œâ”€â”€ crew.py                # CrewAI crew orchestration
â”‚   â”‚   â”‚   â”œâ”€â”€ healing_agents.py      # Healing-specific agents
â”‚   â”‚   â”‚   â””â”€â”€ healing_tasks.py       # Healing-specific tasks
â”‚   â”‚   â”œâ”€â”€ main.py                    # FastAPI application entry point
â”‚   â”‚   â””â”€â”€ requirements.txt           # Python dependencies
â”‚   â””â”€â”€ frontend/
â”‚       â”œâ”€â”€ index.html                 # Web interface
â”‚       â”œâ”€â”€ script.js                  # Frontend logic
â”‚       â””â”€â”€ style.css                  # Styling
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ browser_use_service.py         # BrowserUse AI service (Flask)
â”‚   â”œâ”€â”€ browser_use_tool.py            # Browser automation tools
â”‚   â””â”€â”€ cleanup_docker_containers.py   # Docker cleanup utility
â”œâ”€â”€ robot_tests/                       # Generated test files and reports
â”œâ”€â”€ logs/                              # Application logs
â”œâ”€â”€ config/                            # Configuration files
â”œâ”€â”€ run.sh                             # Startup script
â””â”€â”€ test.sh                            # Testing script
```

## ğŸ› Debugging

When tests fail, detailed logs are automatically saved:

- `robot_tests/{run_id}/log.html` - Step-by-step execution log
- `robot_tests/{run_id}/report.html` - High-level test report
- `robot_tests/{run_id}/output.xml` - Machine-readable results

Open `log.html` in your browser for comprehensive failure analysis.

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details.

### Development Setup

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/amazing-feature`
3. Make your changes
4. Run tests: `./test.sh`
5. Commit: `git commit -m 'Add amazing feature'`
6. Push: `git push origin feature/amazing-feature`
7. Open a Pull Request

Before contributing, please read our [Contributor License Agreement](CLA.md).

## ğŸ“„ License

This project is licensed under the Apache License 2.0 - see the [LICENSE](LICENSE) file for details.

## ğŸ†˜ Support

- ğŸ“š **Documentation**: Check this README and code comments
- ğŸ› **Issues**: Report bugs via GitHub Issues
- ğŸ’¬ **Discussions**: Join our GitHub Discussions
- ğŸ“§ **Email**: Contact the maintainers

## ğŸ¯ Roadmap

- [ ] Support for mobile app testing
- [ ] Integration with CI/CD pipelines
- [ ] Visual test result dashboards
- [ ] Multi-language test generation
- [ ] Advanced AI model fine-tuning
- [ ] Cloud deployment options

## â­ Show Your Support

If Mark 1 helps streamline your testing workflow, please consider:
- â­ Starring this repository
- ğŸ› Reporting issues
- ğŸ’¡ Suggesting new features
- ğŸ¤ Contributing code

---

**Built with â¤ï¸ for the test automation community**
