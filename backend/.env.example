# The model provider to use. Can be "online" or "local".
MODEL_PROVIDER=online

# The online model to use (e.g., "gemini-1.5-pro-latest").
# This is only used if MODEL_PROVIDER is "online".
ONLINE_MODEL=gemini-1.5-pro-latest

# The local model to use with Ollama (e.g., "llama3", "codellama").
# This is only used if MODEL_PROVIDER is "local".
LOCAL_MODEL=llama3
