# Architecture Overview

Mark 1 uses a sophisticated multi-agent AI system to transform natural language into working Robot Framework tests.

## System Architecture

### PlantUML Diagram

```plantuml
@startuml Mark1_Architecture_Verified

!define RECTANGLE_COLOR #E1F5FE
!define AGENT_COLOR #FFF9C4
!define SERVICE_COLOR #C8E6C9
!define DOCKER_COLOR #BBDEFB

skinparam backgroundColor #FAFAFA
skinparam roundcorner 10
skinparam shadowing true

' Title
title Mark 1 - Natural Language to Robot Framework Architecture\n(Multi-Agent AI System - Verified Implementation)

' User and Frontend
actor "User" as user
rectangle "Frontend (Web UI)" as frontend #E1F5FE {
  component "index.html\nscript.js" as webui
  component "Server-Sent Events\n(SSE Stream)" as sse
}

' Backend API Layer
rectangle "FastAPI Backend (Port 5000)" as backend #E1F5FE {
  component "API Endpoints" as api
  note right of api
    POST /generate-and-run
    GET /docker-status
    POST /rebuild-docker-image
    DELETE /test/containers/cleanup
  end note
  
  component "Workflow Service" as workflow
  note right of workflow
    stream_generate_and_run()
    Runs CrewAI in Thread
    Uses Queue for communication
    Streams progress via SSE
  end note
  
  queue "Thread Queue" as threadqueue
}

' Multi-Agent AI System (CrewAI) - Running in Thread
rectangle "Multi-Agent AI System (CrewAI)\n[Runs in Separate Thread]" as crewai #FFF9C4 {
  component "Task 0: Step Planner" as agent1
  note right of agent1
    step_planner_agent()
    Analyzes user query
    Breaks into JSON steps
    Only explicit actions
  end note
  
  component "Task 1: Element Identifier" as agent2
  note right of agent2
    element_identifier_agent()
    Uses BatchBrowserUseTool
    Finds ALL elements (one session)
    Vision-based detection
  end note
  
  component "Task 2: Code Assembler" as agent3
  note right of agent3
    code_assembler_agent()
    Transforms to Robot code
    Library-specific syntax
    Output extracted here
  end note
  
  component "Task 3: Code Validator" as agent4
  note right of agent4
    code_validator_agent()
    Validates syntax
    Best practices check
    Returns JSON validation
  end note
}

' Library Context System
rectangle "Library Context System" as libcontext #C8E6C9 {
  component "get_library_context()" as factory
  component "BrowserLibraryContext\n(Playwright)" as browser
  component "SeleniumLibraryContext\n(Legacy)" as selenium
  factory --> browser : ROBOT_LIBRARY=browser
  factory --> selenium : ROBOT_LIBRARY=selenium
}

' BrowserUse Service - SEPARATE PROCESS
rectangle "BrowserUse Service\n[Separate Flask Process - Port 4999]" as browseruse #C8E6C9 {
  component "Flask API" as flaskapi
  note right of flaskapi
    GET /health
    POST /submit (legacy)
    POST /workflow (primary)
    GET /query/<task_id>
  end note
  
  queue "Task Queue\n(In-Memory)" as taskqueue
  
  component "Async Task Processor" as taskproc
  note right of taskproc
    ThreadPoolExecutor
    process_task()
    Handles workflows
  end note
  
  component "Browser Session\n(Playwright)" as vision
  note right of vision
    AI vision engine
    Context-aware navigation
    Popup handling
    Element detection
  end note
  
  component "Locator Generator" as locgen
  note right of locgen
    Multiple strategies:
    ID, name, CSS, XPath
    aria-*, data-*, role
    JavaScript validation
  end note
}

' Docker Execution
rectangle "Docker Execution Layer" as docker #BBDEFB {
  component "Image: robot-test-runner:latest" as builder
  component "Container: robot-test-{run_id}" as container
  component "Robot Framework\nExecutor" as executor
  note right of executor
    Isolated environment
    Mounts robot_tests/
    Executes: robot --outputdir
    Extracts from output.xml
  end note
}

' Results and Reports
rectangle "Test Results" as results #E1F5FE {
  storage "test.robot" as robotfile
  storage "output.xml" as outputxml
  storage "log.html" as loghtml
  storage "report.html" as reporthtml
}

' LLM Provider
cloud "LLM Provider" as llm {
  component "Google Gemini\n(gemini-2.5-flash)" as gemini
  component "Ollama\n(Local Models)" as ollama
}

' ===== FLOW CONNECTIONS =====

' Frontend to Backend
user --> webui : 1. Enter query
webui --> sse : 2. Open SSE connection
sse --> api : 3. POST /generate-and-run

' Backend to Workflow
api --> workflow : 4. Invoke workflow service

' Workflow spawns thread
workflow --> threadqueue : 5. Queue for thread\ncommunication
threadqueue --> agent1 : 6. Start CrewAI\n(in thread)

' CrewAI Sequential Flow
agent1 --> agent2 : 7. JSON steps\n(Task 0â†’1)
agent2 --> agent3 : 8. Steps + locators\n(Task 1â†’2)
agent3 --> agent4 : 9. Robot code\n(Task 2â†’3)
agent4 --> threadqueue : 10. Validation result\n(via queue)

' Library Context Integration
workflow --> factory : Load library context
factory --> agent1 : Inject to RobotAgents()
factory --> agent2 : Library-specific\ninstructions
factory --> agent3 : Syntax templates

' Agent 2 to BrowserUse Service
agent2 --> flaskapi : 11. POST /workflow\n(batch elements)
flaskapi --> taskqueue : 12. Create task
taskqueue --> taskproc : 13. Process async
taskproc --> vision : 14. Open browser\n(single session)
vision --> locgen : 15. Extract locators
locgen --> vision : 16. Validate with JS
vision --> taskproc : 17. Complete
taskproc --> taskqueue : 18. Update task status
agent2 --> flaskapi : 19. GET /query/{task_id}\n(poll until complete)
flaskapi --> agent2 : 20. Return locator_mapping

' LLM Integration
agent1 --> llm : Query planning
agent3 --> llm : Code generation
agent4 --> llm : Validation

' Workflow to Docker
threadqueue --> workflow : 21. Get robot_code\n(from queue)
workflow --> robotfile : 22. Save to\nrobot_tests/{run_id}/
workflow --> docker : 23. Execute test
docker --> builder : 24. Build image\n(first time only)
builder --> container : 25. Create container
container --> executor : 26. Run robot command
executor --> results : 27. Generate reports

' Results back to user
results --> workflow : 28. Extract from output.xml
workflow --> sse : 29. Stream results
sse --> webui : 30. Update UI
webui --> user : 31. Display results\n+ report links

@enduml
```

## Architecture Validation Report

### âœ… Verified Components (Factually Correct)

1. **Frontend Layer**
   - âœ… HTML/JavaScript interface (`index.html`, `script.js`)
   - âœ… Server-Sent Events (SSE) for real-time progress
   - âœ… Connects to `/generate-and-run` endpoint

2. **FastAPI Backend**
   - âœ… Main endpoints: `POST /generate-and-run`, `GET /docker-status`, `POST /rebuild-docker-image`
   - âœ… Mounts `/reports` for static HTML reports
   - âœ… Uses `StreamingResponse` for SSE

3. **Multi-Agent System (CrewAI)**
   - âœ… **Agent 1: Step Planner** (`step_planner_agent()`) - Breaks query into structured JSON steps
   - âœ… **Agent 2: Element Identifier** (`element_identifier_agent()`) - Uses BatchBrowserUseTool
   - âœ… **Agent 3: Code Assembler** (`code_assembler_agent()`) - Converts to Robot Framework
   - âœ… **Agent 4: Code Validator** (`code_validator_agent()`) - Validates syntax
   - âœ… Sequential processing: Task 0â†’1â†’2â†’3 (planâ†’identifyâ†’assembleâ†’validate)

4. **Library Context System**
   - âœ… Factory function: `get_library_context(library_type)`
   - âœ… Supports: `BrowserLibraryContext` (Playwright) and `SeleniumLibraryContext`
   - âœ… Injected into agents at initialization

5. **BrowserUse Service (Microservice)**
   - âœ… Flask application running on port 4999 (default)
   - âœ… Endpoints: 
     - `GET /health` - Health check
     - `POST /submit` - Single element tasks (legacy)
     - `POST /workflow` - Batch workflow (primary)
     - `GET /query/<task_id>` - Poll task status
   - âœ… Uses Playwright for browser automation
   - âœ… AI vision-based element detection
   - âœ… Generates multiple locator strategies (ID, name, CSS, XPath, aria-*, data-*)
   - âœ… F12-style validation with JavaScript evaluation

6. **Docker Execution**
   - âœ… Image: `robot-test-runner:latest`
   - âœ… Container naming: `robot-test-{run_id}`
   - âœ… Mounts `robot_tests/` directory
   - âœ… Executes `robot --outputdir /app/robot_tests/{run_id} /app/robot_tests/{run_id}/test.robot`
   - âœ… Extracts results from `output.xml`, `log.html`, `report.html`

7. **LLM Integration**
   - âœ… Supports Google Gemini (`gemini/gemini-2.5-flash`)
   - âœ… Supports Ollama for local models
   - âœ… Configured via `MODEL_PROVIDER` and `GEMINI_API_KEY`

### ğŸ”§ Corrections to Diagram

**Issue 1: BrowserUse Service is NOT a "Microservice" in traditional sense**
- **Reality**: It's a separate Flask application that must be run independently
- **Fix**: Label should be "BrowserUse Service (Separate Process)" not "Microservice"

**Issue 2: Missing Query Polling Mechanism**
- **Reality**: Agent 2 submits to `/workflow` endpoint, then polls `/query/{task_id}` until complete
- **Fix**: Add intermediate "Task Queue" component showing async task processing

**Issue 3: Workflow Service Threading**
- **Reality**: `stream_generate_and_run()` runs CrewAI in a separate thread and uses Queue for communication
- **Fix**: Show thread boundary between API and CrewAI execution

**Issue 4: Task Output Indices**
- **Reality**: Code is extracted from `crew_with_results.tasks[2]` (Code Assembler), validation from `tasks[3]`
- **Fix**: Note shows correct task ordering

### ASCII Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User Query     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     FastAPI Backend                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Multi-Agent AI System       â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚ 1. Step Planner Agent   â”‚  â”‚  â”‚
â”‚  â”‚  â”‚ 2. Element Finder Agent â”‚  â”‚  â”‚
â”‚  â”‚  â”‚ 3. Code Assembly Agent  â”‚  â”‚  â”‚
â”‚  â”‚  â”‚ 4. Code Validator Agent â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   BrowserUse Service (AI Vision)    â”‚
â”‚   - Element Detection               â”‚
â”‚   - Context Understanding           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Docker Container                  â”‚
â”‚   - Robot Framework Execution       â”‚
â”‚   - Isolated Environment            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Test Results                      â”‚
â”‚   - .robot file                     â”‚
â”‚   - HTML reports                    â”‚
â”‚   - Execution logs                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Core Components

### 1. Multi-Agent AI System

Four specialized agents work together:

**Step Planner Agent**
- Analyzes natural language query
- Breaks down into structured test steps
- Only includes explicitly mentioned actions

**Element Finder Agent**
- Coordinates with BrowserUse service
- Finds web elements using AI vision
- Generates stable locators

**Code Assembly Agent**
- Transforms steps into Robot Framework code
- Applies library-specific syntax
- Adds proper error handling

**Code Validator Agent**
- Validates generated code syntax
- Checks for common errors
- Ensures best practices

### 2. BrowserUse Service

AI-powered browser automation:
- Vision-based element detection
- Context-aware navigation
- Batch processing (finds all elements in one session)
- 95%+ accuracy rate

### 3. Library Context System

Dynamic code generation for different Robot Framework libraries:

**Supported Libraries:**
- **Browser Library (Playwright)** - Recommended for modern websites
- **SeleniumLibrary** - Legacy support for compatibility

**Key Features:**
- Dynamic keyword extraction from installed libraries
- Library-specific best practices and templates
- Automatic syntax adaptation
- Extensible architecture for future libraries

**How it works:**
1. Configuration specifies library (`ROBOT_LIBRARY=browser` or `selenium`)
2. Library context loaded at startup
3. AI agents receive library-specific instructions
4. Generated code uses correct keywords and syntax
5. Validation ensures library-specific correctness

**Example - Same query, different libraries:**

*Browser Library output:*
```robot
New Browser    chromium    headless=False
New Context    viewport=None
New Page    https://example.com
Fill Text    name=q    search term
```

*SeleniumLibrary output:*
```robot
Open Browser    https://example.com    chrome
Input Text    name=q    search term
```

### 4. Docker Execution

Isolated test execution:
- Clean environment per test
- No interference between runs
- Consistent, reproducible results

## Data Flow

1. **User submits query** via web interface or API
2. **Step Planner** analyzes and structures the query
3. **Element Finder** uses BrowserUse to locate elements
4. **Code Assembly** generates Robot Framework code
5. **Code Validator** checks and validates code
6. **Docker** executes test in isolated container
7. **Results** returned with logs and reports

## Technology Stack

- **Backend**: FastAPI (Python)
- **AI Framework**: CrewAI (multi-agent orchestration)
- **LLM**: Google Gemini or Ollama (local)
- **Browser Automation**: BrowserUse (AI vision with Playwright)
- **Test Framework**: Robot Framework
- **Containerization**: Docker
- **Test Libraries**: 
  - Browser Library (Playwright) - Recommended
  - SeleniumLibrary - Legacy support
- **Locator Validation**: Playwright (for Browser Library) or JavaScript (for SeleniumLibrary)

## Key Design Decisions

### Why Multi-Agent?

Specialized agents handle specific tasks better than a single monolithic system:
- Better accuracy per task
- Easier to debug and improve
- Modular and maintainable

### Why AI Vision?

Traditional element detection (record-and-playback) fails on dynamic websites. AI vision:
- Understands context and intent
- Adapts to website changes
- Generates stable locators

### Why Docker?

Isolated execution ensures:
- No dependency conflicts
- Clean state per test
- Reproducible results
- Easy CI/CD integration

## Performance Characteristics

- **Test Generation**: 15-30 seconds
- **Element Detection**: 5-15 seconds (batch processing)
- **Code Validation**: 1-2 seconds
- **Test Execution**: Varies by website

## Scalability

Current limitations:
- One test at a time (sequential processing)
- Single browser session per test

Future improvements:
- Parallel test generation
- Distributed execution
- Caching and optimization

## Security Model

- API keys stored locally only
- No data persistence (stateless)
- Docker isolation for execution
- Optional local AI models (Ollama)

## Library Context Architecture

Mark 1 uses a flexible library context system to support multiple Robot Framework libraries:

```
src/backend/crew_ai/library_context/
â”œâ”€â”€ base.py                    # Abstract base class
â”œâ”€â”€ browser_context.py         # Browser Library (Playwright)
â”œâ”€â”€ selenium_context.py        # SeleniumLibrary
â”œâ”€â”€ dynamic_context.py         # Dynamic keyword extraction
â””â”€â”€ __init__.py               # Factory function
```

**Adding a new library:**

1. Create new context class:
```python
# my_library_context.py
from .base import LibraryContext

class MyLibraryContext(LibraryContext):
    @property
    def library_name(self) -> str:
        return "MyLibrary"
    
    @property
    def planning_context(self) -> str:
        return "Keywords and best practices..."
    
    # Implement other required methods
```

2. Register in factory:
```python
# __init__.py
def get_library_context(library_type: str):
    if library_type == "mylibrary":
        return MyLibraryContext()
```

3. Update configuration:
```python
# config.py
@validator('ROBOT_LIBRARY')
def validate_robot_library(cls, v):
    if v.lower() not in ['selenium', 'browser', 'mylibrary']:
        raise ValueError(...)
```

## Extension Points

Mark 1 is designed to be extensible:

1. **New Robot Framework Libraries**
   - Add library context in `library_context/`
   - Implement LibraryContext interface
   - Update configuration validator
   - Example: AppiumLibrary for mobile testing

2. **New AI Models**
   - Configure in `.env`
   - Supported via LiteLLM
   - Example: Claude, GPT-4, local models

3. **Custom Agents**
   - Add to `agents.py`
   - Integrate in workflow
   - Example: Performance testing agent

4. **New Test Types**
   - Extend agent capabilities
   - Add new task definitions
   - Example: API testing, mobile testing

## Learn More

- [Configuration Guide](CONFIGURATION.md)
- [Best Practices](BEST_PRACTICES.md)
- [Contributing Guide](../CONTRIBUTING.md)

---

## Detailed Code Flow Analysis

### Step-by-Step Execution Trace

#### Phase 1: User Input â†’ API (Frontend â†’ Backend)
```
1. User enters: "Search for shoes on Flipkart"
2. script.js: Opens EventSource to /generate-and-run
3. endpoints.py: generate_and_run_streaming()
4. Returns: StreamingResponse(stream_generate_and_run())
```

#### Phase 2: Workflow Initialization (API â†’ Thread)
```
5. workflow_service.py: stream_generate_and_run()
6. Creates Thread: run_workflow_in_thread()
7. Thread runs: run_agentic_workflow()
8. Queue created for thread<->async communication
```

#### Phase 3: CrewAI Execution (4 Sequential Agents)
```
9. crew.py: run_crew()
10. Loads: get_library_context(ROBOT_LIBRARY)
11. Initializes: RobotAgents(model_provider, model_name, library_context)

Agent 1 (Task 0): step_planner_agent
  Input: "Search for shoes on Flipkart"
  Output: [
    {"keyword": "New Browser", "browser": "chromium"},
    {"keyword": "New Page", "value": "https://flipkart.com"},
    {"keyword": "Fill Text", "element_description": "search box", "value": "shoes"},
    {"keyword": "Keyboard Key", "value": "Enter"}
  ]

Agent 2 (Task 1): element_identifier_agent
  Input: Steps from Agent 1
  Action: Calls BatchBrowserUseTool.run()
  â†’ browser_use_tool.py: Submits to POST /workflow
  â†’ browser_use_service.py: /workflow endpoint
  â†’ Creates task_id, adds to task queue
  â†’ process_task() in ThreadPoolExecutor
  â†’ Opens Playwright browser (single session)
  â†’ AI Agent navigates and finds ALL elements
  â†’ Validates locators with JavaScript
  â†’ Returns: locator_mapping
  Agent 2 polls: GET /query/{task_id} until complete
  Output: Steps + locators added

Agent 3 (Task 2): code_assembler_agent
  Input: Steps with locators
  Uses: library_context.code_assembly_context
  Output: Complete .robot file (extracted from crew.tasks[2].output.raw)

Agent 4 (Task 3): code_validator_agent
  Input: Robot code
  Output: {"valid": true, "reason": "Code is valid"}
```

#### Phase 4: Code Saving & Docker Execution
```
12. workflow_service.py: Extracts robot_code from tasks[2]
13. Generates run_id: uuid.uuid4()
14. Saves: robot_tests/{run_id}/test.robot
15. docker_service.py: get_docker_client()
16. build_image() - only if image doesn't exist
17. run_test_in_container(run_id, test_filename)
18. Creates container: robot-test-{run_id}
19. Executes: robot --outputdir /app/robot_tests/{run_id} test.robot
20. Waits for completion
21. Extracts results from output.xml using XML parsing
22. Cleans up container
```

#### Phase 5: Results Streaming (Docker â†’ User)
```
23. workflow_service.py: Yields results to queue
24. stream_generate_and_run(): Reads from queue
25. Formats: f"data: {json.dumps(event)}\n\n"
26. SSE stream sends to browser
27. script.js: eventSource.onmessage
28. Updates UI with results
29. Shows links: /reports/{run_id}/log.html
```

### Key Architectural Decisions Verified

1. **Threading Model**: CrewAI runs in separate thread to avoid blocking async FastAPI
   - Location: `workflow_service.py:run_workflow_in_thread()`
   - Uses: Python Queue for inter-thread communication

2. **BrowserUse Service Independence**: Completely separate Flask process
   - Must be started independently: `python tools/browser_use_service.py`
   - Communication: HTTP REST API (not direct imports)
   - Async processing: ThreadPoolExecutor for concurrent tasks

3. **Task Ordering**: Sequential CrewAI execution
   - Crew definition: `Process.sequential`
   - Task indices: 0=plan, 1=identify, 2=assemble, 3=validate
   - Code extracted from: `crew_with_results.tasks[2].output.raw`

4. **Library Context Injection**: Happens at agent initialization
   - Factory: `get_library_context(library_type)`
   - Injected: `RobotAgents(model_provider, model_name, library_context)`
   - Used by: All 4 agents for library-specific syntax

5. **Docker Isolation**: Each test gets fresh container
   - Naming: `robot-test-{run_id}` (unique UUID)
   - Cleanup: `container.remove()` after execution
   - No healing system - locators validated upfront

### Performance Bottlenecks Identified

1. **Sequential Agent Processing**: Agents cannot parallelize
   - Agent 2 waits for Agent 1 completion
   - Total time: Sum of all agent times (~20-30s)

2. **BrowserUse Polling**: Agent 2 polls /query endpoint
   - Poll interval: 5 seconds (default)
   - Could use WebSockets for real-time updates

3. **Docker Image Build**: First-time penalty
   - Build time: 2-5 minutes (one-time)
   - Cached for subsequent runs

4. **Single BrowserUse Task**: Only one workflow at a time
   - Service checks: `len(active_tasks) > 0 â†’ 429 Busy`
   - Could support queue for multiple requests

### Security Considerations Verified

1. âœ… **No data persistence**: Tasks stored in-memory only
2. âœ… **API key isolation**: GEMINI_API_KEY in .env, not in code
3. âœ… **Docker isolation**: Each test runs in clean container
4. âœ… **CORS enabled**: `allow_origins=["*"]` - OK for local dev, should restrict in production
5. âš ï¸ **BrowserUse Service**: No authentication - should add API key validation

---

**Diagram Status**: âœ… **VERIFIED** - All components, connections, and flows match actual implementation

---

## Docker Execution Layer - Detailed Verification

### âœ… Component Verification

#### 1. **Image: `robot-test-runner:latest`** âœ…
**Verified in**: `docker_service.py` Line 8, `Dockerfile`

```python
IMAGE_TAG = "robot-test-runner:latest"
```

**Image Contents** (from Dockerfile):
- **Base**: Python 3.12-slim
- **Package Manager**: UV (10-100x faster than pip)
- **Robot Framework**: Core + SeleniumLibrary + Browser Library
- **Browsers**: Playwright Chromium + Google Chrome
- **Display**: Xvfb for headless execution
- **Healing Support**: Virtual display for Chrome validation

**Build Process**:
```python
def build_image(client: docker.DockerClient) -> Generator[Dict[str, Any], None, None]:
    try:
        client.images.get(IMAGE_TAG)  # Check if exists
        yield {"status": "running", "message": "Using existing container image..."}
        return  # Skip build if exists
    except docker.errors.ImageNotFound:
        # Build only if image doesn't exist
        build_logs = client.api.build(path=DOCKERFILE_PATH, tag=IMAGE_TAG, rm=True, decode=True)
```

**âœ… Diagram Accuracy**: "Build image (first time only)" - CORRECT

---

#### 2. **Container: `robot-test-{run_id}`** âœ…
**Verified in**: `docker_service.py` Lines 116-128

```python
container_config = {
    "image": IMAGE_TAG,
    "command": robot_command,
    "volumes": {os.path.abspath(ROBOT_TESTS_DIR): {'bind': '/app/robot_tests', 'mode': 'rw'}},
    "working_dir": "/app",
    "detach": True,
    "auto_remove": False,
    "name": f"robot-test-{run_id}"  # Unique name per test
}
```

**Container Naming Strategy**:
- Pattern: `robot-test-{run_id}` where `run_id = uuid.uuid4()`
- Purpose: Unique identification, no conflicts
- Cleanup: Explicit removal after execution (not auto_remove)

**Pre-execution Cleanup**:
```python
# Lines 137-149: Clean up any existing container with same name
try:
    existing_container = client.containers.get(container_name)
    existing_container.remove(force=True)  # Force remove if exists
except docker.errors.NotFound:
    pass  # No existing container, proceed
```

**âœ… Diagram Accuracy**: Container naming pattern - CORRECT

---

#### 3. **Robot Framework Executor** âœ…
**Verified in**: `docker_service.py` Lines 105-108

```python
robot_command = [
    "robot", 
    "--outputdir", f"/app/robot_tests/{run_id}", 
    f"/app/robot_tests/{run_id}/{test_filename}"
]
```

**Execution Flow**:
1. Container created with `detach=True` (runs in background)
2. Command executes: `robot --outputdir /app/robot_tests/{run_id} /app/robot_tests/{run_id}/test.robot`
3. `container.wait()` blocks until completion (Line 160)
4. Exit code extracted: `exit_code = result['StatusCode']`

**Volume Mount**:
```python
"volumes": {
    os.path.abspath(ROBOT_TESTS_DIR): {
        'bind': '/app/robot_tests', 
        'mode': 'rw'  # Read-write for report generation
    }
}
```

**Host Path**: `{project_root}/robot_tests/`
**Container Path**: `/app/robot_tests/`
**Result**: Test files and reports accessible from both host and container

**âœ… Diagram Accuracy**: "Executes: robot --outputdir" - CORRECT

---

#### 4. **Results Extraction** âœ…
**Verified in**: `docker_service.py` Lines 173-259

**Critical Design Decision**: NO container.logs() usage
```python
# ContainerLogsInterceptor wraps container to prevent logs() calls
container = ContainerLogsInterceptor(container)

# Logs extracted from Robot Framework files instead:
robot_logs = _extract_robot_framework_logs(output_xml_path, log_html_path, exit_code)
```

**Why Not Container Logs?**
- Docker logs can be truncated or corrupted
- Robot Framework generates structured XML/HTML
- More reliable and detailed information

**Files Generated**:
```python
output_xml_path = os.path.join(ROBOT_TESTS_DIR, run_id, "output.xml")
log_html_path = os.path.join(ROBOT_TESTS_DIR, run_id, "log.html")
report_html_path = os.path.join(ROBOT_TESTS_DIR, run_id, "report.html")
```

**Test Result Determination** (Lines 185-207):
```python
# Parse output.xml to determine pass/fail
tree = ET.parse(output_xml_path)
root = tree.getroot()

# Check statistics section for overall pass/fail count
stats = root.find('.//statistics/total/stat')
if stats is not None:
    fail_count = int(stats.get('fail', '0'))
    pass_count = int(stats.get('pass', '0'))
    tests_passed = fail_count == 0 and pass_count > 0
```

**âœ… Diagram Accuracy**: "Extracts from output.xml" - CORRECT

---

### ğŸ” Additional Verification Findings

#### Container Lifecycle Management

**1. Creation** (Line 153):
```python
container = client.containers.run(**container_config)
# Returns: Container object with unique ID
```

**2. Execution Monitoring** (Line 160):
```python
result = container.wait()  # Blocks until completion
exit_code = result['StatusCode']
```

**3. Cleanup** (Lines 166-173):
```python
try:
    container.remove()  # Explicit cleanup
except docker.errors.NotFound:
    pass  # Already removed
```

**4. Emergency Cleanup** (Lines 255-265):
```python
# If exception occurs during execution
if container:
    try:
        container.remove(force=True)  # Force remove
    except Exception:
        pass  # Log but don't fail
```

---

#### Healing Support Configuration

**Healing-Specific Settings** (Lines 129-135):
```python
if enable_healing:
    container_config["environment"] = {
        "HEALING_ENABLED": "true",
        "CHROME_HEADLESS": "true",
        "DISPLAY": ":99"  # Virtual display
    }
    container_config["shm_size"] = "2g"  # Chrome stability
```

**Note**: Current implementation has healing support infrastructure but it's not actively used (locators validated upfront).

---

#### Orphaned Container Cleanup

**Function**: `cleanup_test_containers()` (Lines 376-397)
```python
def cleanup_test_containers(client: docker.DockerClient):
    # Find all containers with robot-test- prefix
    containers = client.containers.list(all=True, filters={"name": "robot-test-"})
    
    for container in containers:
        container.remove(force=True)  # Force remove all matches
```

**Trigger**: 
- Manual: `DELETE /test/containers/cleanup` endpoint
- Automatic: If container creation fails due to name conflict

---

### ğŸ“Š Docker Execution Flow (Verified)

```
1. workflow_service.py calls: run_test_in_container(client, run_id, test_filename)
   â†“
2. docker_service.py:
   â”œâ”€ Check if image exists (IMAGE_TAG = "robot-test-runner:latest")
   â”œâ”€ Build image if not found (one-time, ~2-5 min)
   â”œâ”€ Clean up existing container with same name (if any)
   â”œâ”€ Create container: robot-test-{run_id}
   â”‚   â”œâ”€ Command: ["robot", "--outputdir", f"/app/robot_tests/{run_id}", f".../{test_filename}"]
   â”‚   â”œâ”€ Volume: {host_path}/robot_tests â†’ /app/robot_tests (rw)
   â”‚   â”œâ”€ Working dir: /app
   â”‚   â””â”€ Detach: True (background execution)
   â”œâ”€ Wait for completion: container.wait()
   â”œâ”€ Get exit code: result['StatusCode']
   â”œâ”€ Parse output.xml for test results (XML parsing)
   â”œâ”€ Extract logs from Robot Framework files (NOT Docker logs)
   â”œâ”€ Cleanup container: container.remove()
   â””â”€ Return: {"status": "complete", "test_status": "passed|failed", "result": {...}}
   â†“
3. Results streamed back to user via SSE
```

---

### ğŸ¯ Diagram Updates Required: NONE

The diagram accurately represents:
- âœ… Image naming: `robot-test-runner:latest`
- âœ… Container naming pattern: `robot-test-{run_id}`
- âœ… Build process: "first time only"
- âœ… Execution command: `robot --outputdir`
- âœ… Results extraction: from `output.xml`
- âœ… Volume mounting: `robot_tests/` directory
- âœ… Isolated environment

---

### ğŸ”§ Implementation Details Not in Diagram (But Worth Noting)

1. **Container Logs Interceptor**: Prevents accidental use of `container.logs()` (anti-pattern)
2. **Pre-execution Cleanup**: Removes containers with conflicting names
3. **Healing Infrastructure**: Container config supports healing but not currently active
4. **Emergency Cleanup**: Removes container even if execution fails
5. **XML Parsing**: Uses statistics section for accurate pass/fail determination
6. **Shared Memory**: `shm_size="2g"` for Chrome browser stability

---

**Docker Layer Verification Status**: âœ… **100% ACCURATE** - All diagram elements match implementation
